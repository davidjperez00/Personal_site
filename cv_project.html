<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Computer Vision Math Equation</title>
        <script src="https://kit.fontawesome.com/a03377a90b.js" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="styles/cvproject.css">
         <!-- Google fonts (Next 2 Lines)-->
         <link rel="preconnect" href="https://fonts.gstatic.com">
         <link href="https://fonts.googleapis.com/css2?family=Crimson+Text:wght@600&family=Nunito:wght@300&display=swap" rel="stylesheet">
    
    </head>

    <header>
        <div class="navbar">
            <a href="index.html">David Jon Perez</a>
            <a href="projects.html">Projects</a>
            <a href="academics.html">Academics</a>
            <a href="contact.html">Contact Me</a>
        </div>
    </header>

    <body>
        <div class="inner-container">
                <h2>Computer Vision Handwriten Math Equation&nbsp;Interpreter </h2>
            <div class="twoGrid">
                <div class="itemOne">
                    <iframe width="350" height="450" src="https://youtube.com/embed/831hzDp_bj4?feature=share" 
                    title="YouTube video player" frameborder="0"
                     allow="accelerometer; autoplay; clipboard-write; encrypted-media;
                    gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>
                <div class="itemTwo">
                    <p>From a high level view this project takes in an image of a basic arithmetic
                      equation and outputs the solution to the equation in the&nbsp;image. <br><br>
                      For instance, suppose an image contains the handwritten equation “5 + 3”.
                      The first step in identifying and solving the equation is identifying
                      characteristics in the image that are either digits or arithmetic operators
                      using a cv2 contour. From here, the image is run through a
                      preprocessing pipeline to convert it into a black and white 28x28 pixel image
                      resembling the MNIST digits dataset as this is the bulk of the training data.
                      After the image has been processed and extracted, a neural network is used to
                      make a prediction on what digit or operator is contained within each image.
                      The images are then sorted based on their position in the original image from
                      left to right. Lastly, the resulting equation, preprocessed images, and inputted
                      image with bounding boxes where the digits and operators were extracted are 
                      displayed as&nbsp;output. <br><br>
                    </p>
                    
                    <a href="https://github.com/davidjperez00/ideal-funicular" target="_blank"><i class="fab fa-github"></i>Github Repository</a>
                </div>
            </div>
            </div>
        <footer>
            &copy;David Perez, 2020
        </footer>
    </body>
</html>